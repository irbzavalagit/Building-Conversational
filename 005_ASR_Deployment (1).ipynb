{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.0 ASR Pipeline Deployment with NVIDIA Riva\n",
    "## (part of Lab 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you'll deploy an ASR pipeline with [NVIDIA Riva](https://developer.nvidia.com/riva). After the models are deployed in Riva, you can issue inference requests to the Riva server from a client.\n",
    "\n",
    "**[5.1 NVIDIA Riva](#5.1-NVIDIA-Riva)<br>**\n",
    "**[5.2 Launch Riva Server](#5.2-Launch-Riva-Server)<br>**\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[5.2.1 Riva Configuration](#5.2.1-Riva-Configuration)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[5.2.2 Exercise: Configure Riva for ASR](#5.2.2-Exercise:-Configure-Riva-for-ASR)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[5.2.3 Riva Start Services](#5.2.3-Riva-Start-Services)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[5.2.4 Riva Available Services Check](#5.2.4-Riva-Available-Services-Check)<br>\n",
    "**[5.3 Riva ASR Service Request](#5.3-Riva-ASR-Service-Request)<br>**\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[5.3.1 Python Client Demo](#5.3.1-Python-Client-Demo)<br>\n",
    "**[5.4 Streaming ASR](#5.4-Streaming-ASR)<br>**\n",
    "**[5.5 Riva Customization Capabilities](#5.5-Riva-Customization-Capabilites)<br>**\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[5.5.1 Word Boosting](#5.5.1-Word-Boosting)<br>\n",
    "**[5.6 Stop Riva Services](#5.6-Stop-Riva-Services)<br>**\n",
    "**[5.7 Shut Down the Kernel](#5.7-Shut-Down-the-Kernel)<br>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook Dependencies\n",
    "The steps in this notebook assume that you have:\n",
    "\n",
    "1. **NGC Credentials**<br>Be sure you have added your NGC credential as described in the [NGC Setup notebook](003_Intro_NGC_Setup.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 5.1 NVIDIA Riva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NVIDIA Riva is a GPU-accelerated speech AI SDK for building and deploying Real-time Speech AI pipelines. It offers a complete workflow to build and customize Speech Recognition and Synthesis pipelines. With the NVIDIA Riva platform, you can:\n",
    "\n",
    "- Build State-of-the-Art speech AI pipelines using pretrained NVIDIA models available at NVIDIA GPU Cloud ([NGC](https://ngc.nvidia.com/catalog/models?orderBy=modifiedDESC&query=%20label%3A%22NeMo%2FPyTorch%22&quickFilter=models&filters=)). Riva provides world-class automatic speech recognition (ASR) and text-to-speech (TTS) that runs in real time.\n",
    "\n",
    "- Customize the pipeline and fine-tune AI models on domain-specific data, with NVIDIA [NeMo](https://github.com/NVIDIA/NeMo) and \n",
    "[TAO Toolkit](https://docs.nvidia.com/tao/tao-toolkit/index.html#tao-toolkit).\n",
    "\n",
    "- Optimize the neural networks performance and latency using [NVIDIA TensorRT](https://developer.nvidia.com/tensorrt).\n",
    "\n",
    "- Deploy Speech AI pipelines with [Triton Inference Server](https://developer.nvidia.com/nvidia-triton-inference-server).\n",
    "\n",
    "For more detailed information on NVIDIA Riva Speech AI, please refer to the [Riva developer documentation](https://docs.nvidia.com/deeplearning/riva/user-guide/docs/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 5.2 Launch Riva Server\n",
    "After the model repository is generated, we are ready to start the Riva server.  \n",
    "\n",
    "NVIDIA Riva provides a [Quick Start Guide](https://docs.nvidia.com/deeplearning/riva/user-guide/docs/quick-start-guide.html#local-deployment-using-quick-start-scripts). For this step, we use Riva Quick Start scripts downloaded from NGC.  The scripts have already been downloaded for the class.  You can download them yourself, either directly from NGC while logged in, or using the NGC command line tool \n",
    "\n",
    "Set `RIVA_QS` to the `riva_quickstart` location:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the Riva Quick Start directory\n",
    "WORKSPACE='/dli_workspace'\n",
    "RIVA_QS = WORKSPACE + \"/riva_quickstart\"\n",
    "RIVA_MODEL_REPO = WORKSPACE + \"/riva-asr-model-repo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls $RIVA_QS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of scripts available for managing Riva services. We can initialize the models using `riva_init.sh`, then start and stop the server with `riva_start.sh` and `riva_stop.sh`. We also need to set flags and values in `config.sh` to specify which services and models we want to initiate and start. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 5.2.1 Riva Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Open [config.sh](dli_workspace/riva_quickstart/config.sh) and note the following important sections:\n",
    "\n",
    "##### Enable/Disable Riva Services\n",
    "For each service, a true value means that the server is enabled for that particular capability.  For example, if we just want to run an ASR server, we can set the `service_enabled_asr` parameter to be `true` and all other parameters `false`.  An enabled service also means that later in the config file, all NGC models listed in the section will be downloaded.\n",
    "```yaml\n",
    "# Enable or Disable Riva Services\n",
    "service_enabled_asr=true\n",
    "service_enabled_nlp=true\n",
    "service_enabled_tts=true\n",
    "```\n",
    "\n",
    "##### Specify the Language\n",
    "You can specify the language code for the models that will be loaded.  The instructions and available language codes are included in the `config.sh` file: \n",
    "```yaml\n",
    "# Language code to fetch models of a specify language\n",
    "# Currently only ASR supports languages other than English\n",
    "# Supported language codes: ar-AR, en-US, en-GB, de-DE, es-ES, es-US, fr-FR, hi-IN, it-IT, ja-JP, ru-RU, ko-KR, pt-BR, zh-CN\n",
    "# for any language other than English, set service_enabled_nlp and service_enabled_tts to False\n",
    "# for multiple languages enter space separated language codes.\n",
    "language_code=(\"en-US\")\n",
    "```\n",
    "\n",
    "For this notebook, we want to load both the English and Spanish models.  To load both, you can change the setting to:<br>\n",
    "```yaml\n",
    "language_code=(\"en-US\", \"es-US\")\n",
    "```\n",
    "\n",
    "##### Set the Encryption Key\n",
    "   We want our encryption consistent for all of our projects, so we want this key to be the same as the one used to export our original model (and it already is!).  For the purposes of this class, this setting won't change.\n",
    "```yaml\n",
    "# Specify the encryption key to use to deploy models\n",
    "MODEL_DEPLOY_KEY=\"tlt_encode\"\n",
    "```\n",
    "\n",
    "##### Set the Model Location\n",
    "`riva_model_loc` should be the folder that contains both the `rmir` folder `models` folders.  This value will need to be changed to the actual absolute path for a given project.\n",
    "```yaml\n",
    "# Custom models produced by NeMo or TLT and prepared using riva-build\n",
    "# may also be copied manually to this location $(riva_model_loc/rmir).\n",
    "#\n",
    "# Models ($riva_model_loc/models)\n",
    "# During the riva_init process, the RMIR files in $riva_model_loc/rmir\n",
    "# are inspected and optimized for deployment. The optimized versions are\n",
    "# stored in $riva_model_loc/models. The riva server exclusively uses these\n",
    "# optimized versions.\n",
    "riva_model_loc=\"/riva-model-repo\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model repo prebuilt location is \"/dli_workspace/riva-asr-model-repo\"\n",
    "!ls $RIVA_MODEL_REPO/models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 5.2.2 Exercise: Configure Riva for ASR\n",
    "\n",
    "Open [config.sh](dli_workspace/riva_quickstart/config.sh) and modify it to:\n",
    "* Deploy only the ASR service \n",
    "* Specify both English and Spanish\n",
    "* Specify the `/dli_workspace/riva-asr-model-repo` model repo location where we've preloaded the ASR models\n",
    "\n",
    "Save your work.\n",
    "\n",
    "If you're not sure what to change, take a peek at the [solution](solutions/ex5.2.2_config.sh)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check your work.  The `diff` comparison in the following cell should have no output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check your work\n",
    "!diff solutions/ex5.2.2_config.sh dli_workspace/riva_quickstart/config.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Quick fix!\n",
    "!cp solutions/ex5.2.2_config.sh dli_workspace/riva_quickstart/config.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2.3 Riva Start Services\n",
    "\n",
    "The `riva_init.sh` script downloads the Riva containers needed, downloads models listed in `config.sh`, and optimizes  models as required with [NVIDIA TensorRT](https://developer.nvidia.com/tensorrt). Since we've already used the ServiceMaker `riva-deploy` tool to optimize the models we are using, `riva_init.sh` won't have much to do, but it is provided here for completeness.\n",
    "\n",
    "The `riva_start.sh` script starts the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize Riva\n",
    "# Models have been preloaded, so TensorRT builds (\"deployment\") will be skipped\n",
    "!cd $RIVA_QS && bash riva_init.sh config.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Riva Start. This will start the server.\n",
    "!cd $RIVA_QS && bash riva_start.sh config.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Riva ASR services should be running when you get \"Riva server is ready...\" (about 1 minute).\n",
    "\n",
    "##### Troubleshooting:\n",
    "If it failed, open a terminal and clean the Riva model repository with:\n",
    "\n",
    "```bash\n",
    "cd /dli_workspace/riva_quickstart && bash riva_clean.sh config.sh\n",
    "```\n",
    "   \n",
    "Run Riva Start Services as explained previously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2.4 Riva Available Services Check\n",
    "\n",
    "To check the exposed Riva services, run the `docker logs riva-speech` command. \n",
    "\n",
    "You should see the following models ready:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "+-------------------------------------------------------------------+---------+--------+\n",
    "| Model                                                             | Version | Status |\n",
    "+-------------------------------------------------------------------+---------+--------+\n",
    "| conformer-en-US-asr-offline                                       | 1       | READY  |\n",
    "| conformer-en-US-asr-offline-ctc-decoder-cpu-streaming-offline     | 1       | READY  |\n",
    "| conformer-en-US-asr-offline-endpointing-streaming-offline         | 1       | READY  |\n",
    "| conformer-en-US-asr-offline-feature-extractor-streaming-offline   | 1       | READY  |\n",
    "| conformer-en-US-asr-streaming                                     | 1       | READY  |\n",
    "| conformer-en-US-asr-streaming-ctc-decoder-cpu-streaming           | 1       | READY  |\n",
    "| conformer-en-US-asr-streaming-endpointing-streaming               | 1       | READY  |\n",
    "| conformer-en-US-asr-streaming-feature-extractor-streaming         | 1       | READY  |\n",
    "| conformer-es-US-asr-offline                                       | 1       | READY  |\n",
    "| conformer-es-US-asr-offline-ctc-decoder-cpu-streaming-offline     | 1       | READY  |\n",
    "| conformer-es-US-asr-offline-endpointing-streaming-offline         | 1       | READY  |\n",
    "| conformer-es-US-asr-offline-feature-extractor-streaming-offline   | 1       | READY  |\n",
    "| conformer-es-US-asr-streaming                                     | 1       | READY  |\n",
    "| conformer-es-US-asr-streaming-ctc-decoder-cpu-streaming           | 1       | READY  |\n",
    "| conformer-es-US-asr-streaming-endpointing-streaming               | 1       | READY  |\n",
    "| conformer-es-US-asr-streaming-feature-extractor-streaming         | 1       | READY  |\n",
    "| riva-punctuation-en-US                                            | 1       | READY  |\n",
    "| riva-punctuation-es-US                                            | 1       | READY  |\n",
    "| riva-trt-conformer-en-US-asr-offline-am-streaming-offline         | 1       | READY  |\n",
    "| riva-trt-conformer-en-US-asr-streaming-am-streaming               | 1       | READY  |\n",
    "| riva-trt-conformer-es-US-asr-offline-am-streaming-offline         | 1       | READY  |\n",
    "| riva-trt-conformer-es-US-asr-streaming-am-streaming               | 1       | READY  |\n",
    "| riva-trt-riva-punctuation-en-US-nn-bert-base-uncased              | 1       | READY  |\n",
    "| riva-trt-riva-punctuation-es-US-nn-bert-base-multilingual-uncased | 1       | READY  |\n",
    "+-------------------------------------------------------------------+---------+--------+\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!docker logs riva-speech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "# 5.3 Riva ASR Service Request \n",
    "To access the Riva API, we need to:\n",
    "1. Start the Riva Speech Skills server. (already done!)\n",
    "2. Install the [Riva Client library](https://github.com/nvidia-riva/tutorials#running-the-riva-client). (already done for this course!)\n",
    "3. Set up requests using the [documentation tutorial example](https://docs.nvidia.com/deeplearning/riva/user-guide/docs/tutorials/asr-python-basics.html) for transcription."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 5.3.1 Python Client Demo\n",
    "\n",
    "Riva ASR service supports a number of options while making a transcription request. Let's learn more about these parameters:\n",
    "\n",
    "- `language_code`: Language of the input audio. \"en-US\" represents English (US); es-US represents Spanish.\n",
    "- `enable_automatic_punctuation`: Run a punctuation and Capitalization at post processing.\n",
    "- `max_alternatives`: Number of top alternative transcriptions to return.\n",
    "- `audio_channel_count`: Number of audio channels. Typical microphones have 1 audio channel.\n",
    "\n",
    "\n",
    "let's load and listen to two audio samples from different languages and query Riva ASR service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the relevant libraries\n",
    "import librosa\n",
    "import IPython.display as ipd\n",
    "from IPython.display import Audio, display\n",
    "import io\n",
    "import riva.client\n",
    "\n",
    "# set audio_samples folder\n",
    "AUDIO_SAMPLES = \"/opt/nvidia-riva/tutorials/audio_samples\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_ENGLISH = AUDIO_SAMPLES + \"/en-US_sample.wav\"\n",
    "\n",
    "with io.open(SAMPLE_ENGLISH, 'rb') as fh:\n",
    "    signal_english = fh.read()\n",
    "ipd.Audio(SAMPLE_ENGLISH) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SPANISH = AUDIO_SAMPLES + \"/es-US_sample.wav\"\n",
    "\n",
    "with io.open(SAMPLE_SPANISH, 'rb') as fh:\n",
    "    signal_spanish = fh.read()\n",
    "ipd.Audio(SAMPLE_SPANISH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect the Riva server port to the client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = riva.client.Auth(uri='localhost:50051')\n",
    "riva_asr = riva.client.ASRService(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a drop-down menu for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a drop-down menu\n",
    "from ipywidgets import Select, HBox, Label, Dropdown\n",
    "from IPython.display import display\n",
    "\n",
    "audio_signal={\"English\": signal_english, \"Spanish\": signal_spanish}\n",
    "language = {\"English\": \"en-US\", \"Spanish\":\"es-US\"}\n",
    "automatic_punctuation = {\"Enable\":True, \"Disable\":False}\n",
    "\n",
    "language_selector=Dropdown(options=['English', 'Spanish'], value='English', description='Language:')\n",
    "punctuation_selector=Dropdown(options=['Enable', 'Disable'], value='Enable',description='Punctuation & Capitalization:')\n",
    "\n",
    "print()\n",
    "print(\"Select the ASR Pipeline to query. Choose one language enable or disable automatic punctuation and capitalization:\")\n",
    "\n",
    "display(HBox([language_selector, punctuation_selector]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure the request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up an offline/batch recognition request\n",
    "config = riva.client.RecognitionConfig()\n",
    "#req.config.encoding = ra.AudioEncoding.LINEAR_PCM    # Audio encoding can be detected from wav\n",
    "#req.config.sample_rate_hertz = 0                     # Sample rate can be detected from wav and resampled if needed\n",
    "config.language_code = language[language_selector.value]                    # Language code of the audio clip\n",
    "config.max_alternatives = 1                       # How many top-N hypotheses to return\n",
    "config.enable_automatic_punctuation = automatic_punctuation[punctuation_selector.value]       # Add punctuation when end of VAD detected\n",
    "config.audio_channel_count = 1                    # Mono channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the transcription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = riva_asr.offline_recognize(audio_signal[language_selector.value], config)\n",
    "asr_best_transcript = response.results[0].alternatives[0].transcript\n",
    "print(\"ASR Transcript:\", asr_best_transcript)\n",
    "\n",
    "print(\"\\n\\nFull Response Message:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 5.4 Streaming ASR\n",
    "The https://github.com/nvidia-riva/python-clients repository includes a directory of Python scripts.  These scripts are included in this course instance. We can use the streaming client script to see how the ASR transcribes words as they are spoken in a stream.  Try it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "\n",
    "data, samplerate = sf.read(\"/dli_workspace/data/audio_sample.wav\", dtype='float32')\n",
    "sf.write(\"/dli_workspace/data/audio_sample_resampled2.wav\", data, samplerate)\n",
    "SAMPLE_ENGLISH_WB=\"/dli_workspace/data/audio_sample_resampled2.wav\"\n",
    "ipd.Audio(SAMPLE_ENGLISH_WB) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set the location of the Python script\n",
    "PYTHON_SCRIPTS = \"/opt/nvidia-riva/python-clients/scripts\"\n",
    "! python $PYTHON_SCRIPTS/asr/riva_streaming_asr_client.py -h    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python $PYTHON_SCRIPTS/asr/riva_streaming_asr_client.py \\\n",
    "        --input-file $SAMPLE_ENGLISH_WB \\\n",
    "        --server \"localhost:50051\" \\\n",
    "        --language-code \"en-US\" \\\n",
    "        --automatic-punctuation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cat output_0.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 5.5 Riva Customization Capabilites\n",
    "\n",
    "\n",
    "The following flow diagram shows the Riva speech recognition pipeline along with the possible customizations.\n",
    "\n",
    "<img src=\"https://docs.nvidia.com/deeplearning/riva/user-guide/docs/_images/riva-asr-pipeline-best-practices.png\" height=50> \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5.1 Word Boosting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "! python $PYTHON_SCRIPTS/asr/transcribe_file_offline.py -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python $PYTHON_SCRIPTS/asr/transcribe_file_offline.py \\\n",
    "        --server \"localhost:50051\" \\\n",
    "        --input-file $SAMPLE_ENGLISH_WB \\\n",
    "        --language-code \"en-US\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python $PYTHON_SCRIPTS/asr/transcribe_file_offline.py\\\n",
    "        --server \"localhost:50051\" \\\n",
    "        --input-file $SAMPLE_ENGLISH_WB \\\n",
    "        --language-code \"en-US\" \\\n",
    "        --boosted-lm-words \"daina\" \\\n",
    "        --boosted-lm-score 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 5.6 Stop Riva Services \n",
    "Stop Riva services.  This shuts down all the containers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Riva Stop. \n",
    "!bash $RIVA_QS/riva_stop.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 5.7 Shut Down the Kernel\n",
    "<h3 style=\"color:red;\">Important!</h3>\n",
    "\n",
    "From the menu above, choose ***Kernel->Shut Down Kernel*** to fully clear GPU memory before moving on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<h2 style=\"color:green;\">Congratulations!</h2>\n",
    "\n",
    "In this notebook, you have:\n",
    "- Launched Riva ASR service\n",
    "- Requested the ASR service using a Python client API\n",
    "\n",
    "This concludes the Lab 1 ASR hands-on material.  The Lab 2 TTS hands-on material begins with an introduction to the [TTS Pipeline](006_TTS_Pipeline.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
