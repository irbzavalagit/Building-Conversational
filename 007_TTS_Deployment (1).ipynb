{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.0 TTS Pipeline Deployment with NVIDIA Riva\n",
    "## (part of Lab 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll deploy TTS with  [NVIDIA Riva](https://developer.nvidia.com/riva). After the model is deployed in Riva, you can issue inference requests to the Riva server from a client.\n",
    "\n",
    "**[7.1 Launch Riva Server](#7.1-Launch-Riva-Server)<br>**\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[7.1.1 Riva Configuration](#7.1.1-Riva-Configuration)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[7.1.2 Exercise: Configure Riva for TTS](#7.1.2-Exercise:-Configure-Riva-for-TTS)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[7.1.3 Riva Start Services](#7.1.3-Riva-Start-Services)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[7.1.4 Riva Available Services Check](#7.1.4-Riva-Available-Services-Check)<br>\n",
    "**[7.2 Riva TTS Service Request](#7.2-Riva-TTS-Service-Request)<br>**\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[7.2.1 Python Client Demo](#7.2.1-Python-Client-Demo)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[7.2.2 Customizing TTS](#7.2.2-Customizing-TTS)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[7.2.3 Exercise: Customize Phonemes](#7.2.3-Exercise:-Customize-Phonemes)<br>\n",
    "**[7.3 Stop Riva Services](#7.3-Stop-Riva-Services)<br>**\n",
    "**[7.4 Shut Down the Kernel](#7.4-Shut-Down-the-Kernel)<br>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook Dependencies\n",
    "The steps in this notebook assume that you have:\n",
    "\n",
    "1. **NGC Credentials**<br>Be sure you have added your NGC credential as described in the [NGC Setup notebook](003_Intro_NGC_Setup.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "# 7.1 Launch Riva Server\n",
    "We'll repeat the process of deployment with Riva that we used for ASR, but this time we will choose to deploy the TTS models instead.  Once again, we'll use the \n",
    "Riva Quick Start scripts downloaded from NGC.  \n",
    "\n",
    "Set `RIVA_QS` to the `riva_quickstart` location.  We'll use a new location for the model repo to just contain the TTS models, as this will be a little faster to deploy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the Riva Quick Start directory\n",
    "WORKSPACE='/dli_workspace'\n",
    "RIVA_QS = WORKSPACE + \"/riva_quickstart\"\n",
    "RIVA_MODEL_REPO = WORKSPACE + \"/riva-tts-model-repo\"\n",
    "!mkdir -p $RIVA_MODEL_REPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls $RIVA_QS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with ASR, we can initialize the models using `riva_init.sh`, then start and stop the server with `riva_start.sh` and `riva_stop.sh`. We also need to set flags and values in `config.sh` to specify which services and models we want to initiate and start. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1.1 Riva Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Open [config.sh](dli_workspace/riva_quickstart/config.sh) and note the following important sections, which may still be set for ASR deployment.  You'll need to modify these sections.\n",
    "\n",
    "##### Enable/Disable Riva Services\n",
    "For each service, a true value means that the server is enabled for that particular capability.  For example, if we just want to run an ASR server, we can set the `service_enabled_tts` parameter to be `true` and all other parameters `false`.  An enabled service also means that later in the config file, all NGC models listed in the section will be downloaded.\n",
    "```yaml\n",
    "# Enable or Disable Riva Services\n",
    "service_enabled_asr=true\n",
    "service_enabled_nlp=true\n",
    "service_enabled_tts=true\n",
    "```\n",
    "\n",
    "##### Specify the Language\n",
    "You can specify the language code for the models that will be loaded.  The instructions and available language codes are included in the `config.sh` file: \n",
    "```yaml\n",
    "# Language code to fetch models of a specify language\n",
    "# Currently only ASR supports languages other than English\n",
    "# Supported language codes: ar-AR, en-US, en-GB, de-DE, es-ES, es-US, fr-FR, hi-IN, it-IT, ja-JP, ru-RU, ko-KR, pt-BR, zh-CN\n",
    "# for any language other than English, set service_enabled_nlp and service_enabled_tts to False\n",
    "# for multiple languages enter space separated language codes.\n",
    "language_code=(\"en-US\")\n",
    "```\n",
    "\n",
    "##### Set the Encryption Key\n",
    "   We want our encryption consistent for all of our projects, so we want this key to be the same as the one used to export our original model (and it already is!).  For the purposes of this class, this setting won't change.\n",
    "```yaml\n",
    "# Specify the encryption key to use to deploy models\n",
    "MODEL_DEPLOY_KEY=\"tlt_encode\"\n",
    "```\n",
    "\n",
    "##### Set the Model Location\n",
    "`riva_model_loc` should be the folder that contains both the `rmir` folder `models` folders.  This value will need to be changed to the actual absolute path for a given project.\n",
    "```yaml\n",
    "# Custom models produced by NeMo or TLT and prepared using riva-build\n",
    "# may also be copied manually to this location $(riva_model_loc/rmir).\n",
    "#\n",
    "# Models ($riva_model_loc/models)\n",
    "# During the riva_init process, the RMIR files in $riva_model_loc/rmir\n",
    "# are inspected and optimized for deployment. The optimized versions are\n",
    "# stored in $riva_model_loc/models. The riva server exclusively uses these\n",
    "# optimized versions.\n",
    "riva_model_loc=\"/riva-model-repo\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 7.1.2 Exercise: Configure Riva for TTS\n",
    "\n",
    "Open [config.sh](dli_workspace/riva_quickstart/config.sh) and modify it to:\n",
    "* Deploy only the TTS service \n",
    "* Specify only English\n",
    "* Specify the `/dli_workspace/riva-tts-model-repo` model repo location where we've preloaded the TTS models\n",
    "\n",
    "Save your work.\n",
    "\n",
    "If you're not sure what to change, take a peek at the [solution](solutions/ex7.1.2_config.sh)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check your work.  The `diff` comparison in the following cell should have no output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check your work\n",
    "!diff solutions/ex7.1.2_config.sh dli_workspace/riva_quickstart/config.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Quick fix!\n",
    "!cp solutions/ex7.1.2_config.sh dli_workspace/riva_quickstart/config.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1.3 Riva Start Services\n",
    "\n",
    "The `riva_init.sh` script downloads the Riva containers needed, downloads models listed in `config.sh`, and optimizes  models as required with [NVIDIA TensorRT](https://developer.nvidia.com/tensorrt). Since we've already used the ServiceMaker `riva-deploy` tool to optimize the models we are using, `riva_init.sh` won't have much to do, but it is provided here for completeness.\n",
    "\n",
    "The `riva_start.sh` script starts the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize Riva (5 minutes)\n",
    "# Models have been preloaded, so TensorRT builds (\"deployment\") will be skipped\n",
    "!cd $RIVA_QS && bash riva_init.sh config.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Riva Start. This will start the server. (15 seconds)\n",
    "!cd $RIVA_QS && bash riva_start.sh config.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Riva ASR services should be running when you get \"Riva server is ready...\"\n",
    "\n",
    "##### Troubleshooting:\n",
    "If it failed, open a terminal and clean the Riva model repository with:\n",
    "\n",
    "```bash\n",
    "cd /dli_workspace/riva_quickstart && bash riva_clean.sh config.sh\n",
    "```\n",
    "   \n",
    "Run Riva Start Services as explained previously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1.4 Riva Available Services Check\n",
    "\n",
    "To check the exposed Riva services, run the `docker logs riva-speech` command. \n",
    "\n",
    "You should see the following models ready:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "+----------------------------------------+---------+--------+\n",
    "| Model                                  | Version | Status |\n",
    "+----------------------------------------+---------+--------+\n",
    "| fastpitch_hifigan_ensemble-English-US  | 1       | READY  |\n",
    "| riva-onnx-fastpitch_encoder-English-US | 1       | READY  |\n",
    "| riva-trt-hifigan-English-US            | 1       | READY  |\n",
    "| spectrogram_chunker-English-US         | 1       | READY  |\n",
    "| tts_postprocessor-English-US           | 1       | READY  |\n",
    "| tts_preprocessor-English-US            | 1       | READY  |\n",
    "+----------------------------------------+---------+--------+\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!docker logs riva-speech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "# 7.2 Riva TTS Service Request\n",
    "To access the Riva API, we need to:\n",
    "1. Start the Riva Speech Skills server. (already done!)\n",
    "2. Install the [Riva Client library](https://github.com/nvidia-riva/tutorials#running-the-riva-client). (already done for this course!)\n",
    "3. Set up requests using the [documentation tutorial example](https://docs.nvidia.com/deeplearning/riva/user-guide/docs/tutorials/tts-python-basics-and-customization-with-ssml.html) for transcription."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 7.2.1 Python Client Demo\n",
    "\n",
    "Riva TTS supports a number of options while making a text-to-speech request to the gRPC endpoint, as shown above. Let’s learn more about these parameters:\n",
    "\n",
    "- `language_code`: Language of the generated audio. en-US represents English (US) and is currently the only language supported OOTB.\n",
    "- `encoding` - Type of audio encoding to generate. Currently, only LINEAR_PCM is supported.\n",
    "- `sample_rate_hz` - Sample rate of the generated audio. Depends on the microphone and is usually 22khz or 44khz.\n",
    "- `voice_name` - Voice used to synthesize the audio. Currently, Riva offers two OOTB voices (English-US.Female-1, English-US.Male-1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import IPython.display as ipd\n",
    "import riva.client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that everything is set up, let's give an input that we want our models to speak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate_hz = 44100\n",
    "\n",
    "def remove_braces(braced_text):\n",
    "    return braced_text.replace(\"{@\",\"\").replace(\"}\",\"\")\n",
    "\n",
    "def tts_predict(text):\n",
    "    auth = riva.client.Auth(uri='localhost:50051')\n",
    "    riva_tts = riva.client.SpeechSynthesisService(auth)\n",
    "    req = { \n",
    "            \"language_code\"  : \"en-US\",\n",
    "            \"encoding\"       : riva.client.AudioEncoding.LINEAR_PCM ,   # Currently only LINEAR_PCM is supported\n",
    "            \"sample_rate_hz\" : sample_rate_hz,                          # Generate 44.1KHz audio\n",
    "            \"voice_name\"     : \"English-US.Female-1\"                    # The name of the voice to generate\n",
    "    }\n",
    "    req[\"text\"] = text\n",
    "    resp = riva_tts.synthesize(**req)\n",
    "    audio_samples = np.frombuffer(resp.audio, dtype=np.int16)\n",
    "    return audio_samples, remove_braces(resp.meta.processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_samples, processed_text =tts_predict(\"Hi, my name is Dana and I work for NVIDIA.\")\n",
    "print(remove_braces(processed_text))\n",
    "ipd.Audio(audio_samples, rate=sample_rate_hz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2.2 Customizing TTS\n",
    "\n",
    "The Speech Synthesis Markup Language (SSML) specification is a markup for directing the performance of the virtual speaker. Riva supports portions of SSML, allowing you to adjust pitch, rate, and pronunciation of the generated audio. SSML support is available only for the FastPitch model at this time. th a different root tag are treated as raw input text.\n",
    "\n",
    "Riva TTS supports the following SSML tags:\n",
    "- The prosody tag, which supports attributes rate, pitch, and volume, through which we can control the rate, pitch, and volume of the generated audio.\n",
    "- The phoneme tag, which allows us to control the pronunciation of the generated audio.\n",
    "- The sub tag, which allows us to replace the pronunciation of the specified word or phrase with a different word or phrase.\n",
    "\n",
    "Let's look at [customization of Riva TTS with these SSML tags](https://docs.nvidia.com/deeplearning/riva/user-guide/docs/tutorials/tts-python-basics-and-customization-with-ssml.html#customizing-riva-tts-audio-output-with-ssml) in some detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prosody tag example\n",
    "text='<speak><prosody pitch=\"0.1\" rate=\"100%\">NVIDIA</prosody></speak>'\n",
    "audio_samples, processed_text = tts_predict(text)\n",
    "print(\"preprocessed text: \", processed_text)\n",
    "ipd.Audio(audio_samples, rate=sample_rate_hz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fix the pronunciation, you can use the phoneme tag.  A list of the TTS phones supported in Riva can be found [here](https://docs.nvidia.com/deeplearning/riva/user-guide/docs/tts/tts-phones.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prosody tag and phoneme tag example\n",
    "text='<speak><prosody pitch=\"0.1\" rate=\"100%\"><phoneme ph=\"ɛnˈvɪdiə\">NVIDIA</phoneme></prosody></speak>'\n",
    "audio_samples, processed_text = tts_predict(text)\n",
    "print(\"preprocessed text: \", processed_text)\n",
    "ipd.Audio(audio_samples, rate=sample_rate_hz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prosody tag and phoneme tag example\n",
    "text='<speak><prosody pitch=\"0.1\" rate=\"100%\">Hi, my name is Dana and I work for <phoneme ph=\"ɛnˈvɪdiə\">NVIDIA</phoneme>.</prosody></speak>'\n",
    "audio_samples, processed_text = tts_predict(text)\n",
    "print(\"preprocessed text: \", processed_text)\n",
    "ipd.Audio(audio_samples, rate=sample_rate_hz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2.3 Exercise: Customize Phonemes\n",
    "Let's revisit the pronunciation we worked on in the NeMo notebook.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_samples, processed_text =tts_predict(\"His name is Adam Grzywaczewski and he works for NVIDIA.\")\n",
    "print(remove_braces(processed_text))\n",
    "ipd.Audio(audio_samples, rate=sample_rate_hz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pronunciations for \"Grzywaczewski\" and \"NVIDIA\" were not correct. Change those pronunciations to \"ɡzɪvɑˈtʃɛvski\" and \"ɛnˈvɪdiə\" using SSML tags.<br>\n",
    "If you get stuck, you can check the [solution](solutions/ex7.2.3.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=#FIXME\n",
    "audio_samples, processed_text = tts_predict(text)\n",
    "print(\"preprocessed text: \", processed_text)\n",
    "ipd.Audio(audio_samples, rate=sample_rate_hz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 7.3 Stop Riva Services \n",
    "We need to stop Riva services as we will be modifying the deployed models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Riva Stop. \n",
    "!bash $RIVA_QS/riva_stop.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 7.4 Shut Down the Kernel\n",
    "<h3 style=\"color:red;\">Important!</h3>\n",
    "\n",
    "From the menu above, choose ***Kernel->Shut Down Kernel*** to fully clear GPU memory before moving on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<h2 style=\"color:green;\">Congratulations!</h2>\n",
    "\n",
    "In this notebook, you have:\n",
    "- Launched Riva TTS service\n",
    "- Requested the TTS service using a Python client API\n",
    "- Customized pronunciations\n",
    "\n",
    "In the nex notebook you'll \"put it all together\" to deploy a [Full Pipline](008_Full_Pipeline.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9750c3195c8cb9412c65c8ba8b36c6ba2b82b23ddd61f39d29e01b403b049680"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
